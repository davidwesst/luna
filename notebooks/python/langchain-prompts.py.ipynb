{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "Examples working to better understand prompts in langchain. Reference: [Prompts](https://python.langchain.com/docs/modules/model_io/prompts/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSCode will prompt for API Key\n",
    "openai_api_key = input(\"Enter OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "Building off of the examples given in the quick start. This example has multiple inputs and does not use an output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# setup the chat model\n",
    "chat_model = ChatOpenAI(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a helpful assistant who translates messages from one language to another. \n",
    "A user will provide a sentence, and you should tranlate the message from {input_language} to {output_language}.\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=chat_prompt\n",
    ")\n",
    "chain.run(input_language=\"English\", output_language=\"Mandarin\", text=\"I like bananas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mad Libs Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a family-friendly mad libs story generator that writes short stories that are no more than 3 paragraphs long for kids and adults to enjoy.\n",
    "A user will give you a subject to write a story about and you should write a {tone} about it.\n",
    "Then, leave placeholders for all of the following types of words that art not about the subject: adjectives, places, and things. They should be marked with << >> with the type of placeholder in between the angle brackets and if it should be pluralized.\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{subject}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=chat_prompt\n",
    ")\n",
    "chain.run(tone=\"funny\", subject=\"A gorilla the size of a house named Audricia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ghostwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not a good use of prompts.\n",
    "# Should be using smaller, isolated prompts, that feed into each other using a sequential chain\n",
    "\n",
    "template = \"\"\"You are a blog ghostwriter that helps technical professionals write markdown blog posts for their websites that expands upon the user's data they provide.\n",
    "A user will give you a {question} for the article to answer, the {answer} to the question, and a {style} in which to write the article.\n",
    "Include markdown image placeholder that contain alt text that can be used as prompts to generate the image.\n",
    "Add subheaders in the text to break up sections of the article.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "ai_question_template = \"What question is the article going to answer?\"\n",
    "ai_question_message_prompt = AIMessagePromptTemplate.from_template(ai_question_template)\n",
    "human_question_template = \"{question}\"\n",
    "human_question_prompt = HumanMessagePromptTemplate.from_template(human_question_template)\n",
    "\n",
    "ai_answer_template = \"What is the answer to the question?\"\n",
    "ai_answer_message_prompt = AIMessagePromptTemplate.from_template(ai_answer_template)\n",
    "human_answer_template = \"{answer}\"\n",
    "human_answer_prompt = HumanMessagePromptTemplate.from_template(human_answer_template)\n",
    "\n",
    "ai_rationale_template = \"What are the key points that justify the answer?\"\n",
    "ai_rationale_message_prompt = AIMessagePromptTemplate.from_template(ai_rationale_template)\n",
    "human_rationale_template = \"{answer}\"\n",
    "human_rationale_prompt = HumanMessagePromptTemplate.from_template(human_rationale_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, ai_question_message_prompt, human_question_prompt, ai_answer_message_prompt, human_answer_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=chat_prompt\n",
    ")\n",
    "output = chain.run(\n",
    "    question=\"Why create the AI podcast about people called \\\"Remember the Human\\\" in 2023?\",\n",
    "    answer=\"Because I, DW, want to get different and real-life opinions about people working with AI to better understand how it has impact on people, rather than just the technology itself.\",\n",
    "    #rationale=\"AI, especially with the Generative AI hype, we are hearing a lot about the potential for AI, but not hearing or seeing practical examples. When you look into it, it is not that AI is coming soon, but rather it is already here and has been for a long time making gradual change to our lives.\",\n",
    "    style=\"Informal, casual, written in the first person, with a bit of humour\"\n",
    ")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
