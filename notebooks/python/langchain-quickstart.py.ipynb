{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [Langchain Python Quickstart](https://python.langchain.com/docs/get_started/quickstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "_Note: Installation steps have been done as part of the devcontainer configuration and setup._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%set_env OPENAI_API_KEY=..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize configuration objects\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Result: \n",
      "'\\n\\nMewsic.'\n",
      "Chat Model Result: \n",
      "'ChatterCat'\n"
     ]
    }
   ],
   "source": [
    "# Try the predict method\n",
    "text = \"Name for a talking cat AI?\"\n",
    "\n",
    "result_llm = llm.predict(text) \n",
    "print(\"LLM Result: \\n% s\" % repr(result_llm)) # repr adds single quotes and enables printing of raw string\n",
    "\n",
    "result_chat_model = chat_model.predict(text)\n",
    "print(\"Chat Model Result: \\n% s\" % repr(result_chat_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Result: \n",
      " content='\\n\\nAI Cat: I think a good name for a talking cat AI would be Meowser.' additional_kwargs={} example=False\n",
      "Chat Model Result: \n",
      " content='WhiskerWise' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Try predict_messages\n",
    "text = \"What is a good name for a talking cat AI?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "result_llm = llm.predict_messages(messages)\n",
    "print(\"LLM Result: \\n % s\" % result_llm)\n",
    "\n",
    "result_chat_model = chat_model.predict_messages(messages)\n",
    "print(\"Chat Model Result: \\n % s\" % result_chat_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a talking video game console powered by AI?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"What is a good name for a talking {item} powered by AI?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(item=\"video game console\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a translation assistant that translates English to Japanese', additional_kwargs={}),\n",
       " HumanMessage(content='My cat is smelly', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "template = \"You are a translation assistant that translates {input_language} to {output_language}\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"Japanese\", text=\"My cat is smelly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', ' bye', ' banana']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\",\")\n",
    "    \n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye, banana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rotten eggs', ' sewage', ' garbage', ' skunk', ' durian']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: These imports are redundant because they were imported in earlier code snippets in this notebook\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\",\")\n",
    "    \n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye, banana\")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists. \n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separate list.\n",
    "ONLY return a comma separate list, and nothing more.\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"things that smell bad\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
